# Show, Attend and Tell: Neural Image Caption Generation with Visual Attention

## A PyTorch implementation

- [x] Create image encoder class
- [x] Create decoder class
- [x] Create dataset loader
- [x] Write main function for training and validation
- [x] Implement attention model
- [x] Implement decoder feed forward function
- [x] Write training function
- [x] Write validation function
- [x] Add BLEU evaluation
- [ ] Update code to use GPU only when available, otherwise use CPU
- [ ] Add performance statistics
- [x] Allow encoder to use resnet-152 and densenet-201

## References

[Show, Attend and Tell](https://arxiv.org/pdf/1502.03044.pdf)

[Original Theano Implementation](https://github.com/kelvinxu/arctic-captions)

[Neural Machine Translation By Jointly Learning to Align And Translate](https://arxiv.org/pdf/1409.0473.pdf)

[Karpathy's Data splits](https://cs.stanford.edu/people/karpathy/deepimagesent/)
